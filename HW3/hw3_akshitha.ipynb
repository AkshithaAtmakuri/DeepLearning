{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBVPb4yMc05M",
    "outputId": "ba79487e-f4fd-4609-82a4-da0e3b623bf8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cAO3U84EGW2L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "2xuVm_W5deTJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setSeed(seed = 1234):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "setSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "GguQxebweOF3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "jsonTrain = \"spoken_train-v1.1.json\"\n",
    "jsonVal = \"spoken_test-v1.1.json\"\n",
    "\n",
    "file_data = pd.read_json(jsonTrain)\n",
    "json_data = file_data['data']\n",
    "\n",
    "size = math.floor(json_data.shape[0]*0.8)\n",
    "trainContents = file_data['data'].loc[0:size]\n",
    "\n",
    "file_data = pd.read_json(jsonVal)\n",
    "json_data = file_data['data']\n",
    "\n",
    "size = math.floor(json_data.shape[0]*0.5)\n",
    "valContents = file_data['data'].loc[0:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "XNWrLQG3GuzI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jsonLists(contents):\n",
    "  texts=[]\n",
    "  questions=[]\n",
    "  answers=[]\n",
    "  for data in contents:\n",
    "    for txt in data['paragraphs']:\n",
    "      text = txt['context']\n",
    "      for qa in txt['qas']: \n",
    "        question = qa['question']\n",
    "        for answer in qa['answers']:\n",
    "          texts.append(text)\n",
    "          questions.append(question)\n",
    "          answers.append(answer)            \n",
    "                  \n",
    "  return texts,questions,answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "paYE-0YTgNHI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainTexts,trainQuestions,trainAnswers=jsonLists(trainContents)\n",
    "valTexts,valQuestions,valAnswers=jsonLists(valContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEndIndx(answers, contexts, doc_stride=150):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        end_idx = answer['answer_start'] + len(answer['text'])\n",
    "        if context[answer['answer_start']:end_idx] == answer['text']:\n",
    "            answer['answer_end'] = end_idx\n",
    "        elif context[answer['answer_start'] - 1:end_idx - 1] == answer['text']:\n",
    "            answer['answer_start'] = answer['answer_start'] - 1\n",
    "            answer['answer_end'] = end_idx - 1\n",
    "        elif context[answer['answer_start'] - 2:end_idx - 2] == answer['text']:\n",
    "            answer['answer_start'] = answer['answer_start'] - 2\n",
    "            answer['answer_end'] = end_idx - 2\n",
    "        \n",
    "        if answer.get('answer_end') and answer['answer_end'] > answer['answer_start']:\n",
    "            start_idx = answer['answer_start']\n",
    "            while start_idx < answer['answer_end']:\n",
    "                end_idx = min(start_idx + doc_stride, len(context))\n",
    "                if context[start_idx:end_idx] == answer['text']:\n",
    "                    answer['answer_end'] = end_idx\n",
    "                    break\n",
    "                start_idx += doc_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "addEndIndx(trainAnswers, trainTexts)\n",
    "addEndIndx(valAnswers, valTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6efgWHFKdMN",
    "outputId": "c8cc3eed-9c0e-476d-cd68-b24873e50d35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast,DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "2-62TIQyH-H0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainEncodings=tokenizer(trainTexts,trainQuestions, truncation=True, padding=True, max_length=512,return_offsets_mapping=True)\n",
    "valEncodings=tokenizer(valTexts,valQuestions, truncation=True, padding=True, max_length=512,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Y_IyfehmLyhN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addTokenPositions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        \n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        \n",
    "        if(answers[i]['answer_end']==0):\n",
    "            end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'])) \n",
    "        else:\n",
    "            end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "                   \n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Y_IyfehmLyhN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "addTokenPositions(trainEncodings, trainAnswers)\n",
    "addTokenPositions(valEncodings, valAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "OPyW7VdgLKn4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "OPyW7VdgLKn4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create datasets\n",
    "trainSet = SquadDataset(trainEncodings)\n",
    "valSet = SquadDataset(valEncodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1CQZvkPj7F7S_EcLapJKNhe8ySn63pACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfCl75yFZnZC",
    "outputId": "eeb99eba-423b-486a-c53f-2edc37901da6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering,DistilBertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert.config.hidden_dropout_prob = 0.1\n",
    "model.bert.config.attention_probs_dropout_prob = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "aKm02qunZ_2-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "trainDataloader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)\n",
    "valDataloader = DataLoader(valSet, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "r1MdTddDZDYb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "lr = 1e-4\n",
    "epochs = 3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [14:58<00:00,  4.09it/s]\n",
      "100%|██████████| 1117/1117 [01:30<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9304\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [14:58<00:00,  4.09it/s]\n",
      "100%|██████████| 1117/1117 [01:29<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0196\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [14:58<00:00,  4.10it/s]\n",
      "100%|██████████| 1117/1117 [01:29<00:00, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, trainDataloader, valDataloader = accelerator.prepare(model, optimizer, trainDataloader, valDataloader)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        batch_losses = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(tqdm(trainDataloader)):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            with accelerator.autocast():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "                loss = outputs[0]\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "            batch_losses.append(loss.detach().item())\n",
    "\n",
    "            if (step + 1) % 4 == 0:\n",
    "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        train_loss = sum(batch_losses) / len(batch_losses)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            batch_losses = []\n",
    "\n",
    "            for batch in tqdm(valDataloader):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "                with accelerator.autocast():\n",
    "                    output = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "                    loss = output[0]\n",
    "\n",
    "                batch_losses.append(loss.detach().item())\n",
    "\n",
    "            val_loss = sum(batch_losses) / len(batch_losses)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Train loss: {train_loss:.4f}')\n",
    "\n",
    "\n",
    "train()\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Processing\n",
    "import jiwer\n",
    "\n",
    "def predictTheAnswer(text,question,model):\n",
    "  wer_sum = 0\n",
    "  num_examples = 0\n",
    "  inputs = tokenizer.encode_plus(question, text, return_tensors='pt',max_length=512, truncation=True).to(device)\n",
    "\n",
    "  outputs = model(**inputs)\n",
    "  answer_start = torch.argmax(outputs[0])\n",
    "  answer_end = torch.argmax(outputs[1]) + 1 \n",
    "\n",
    "  if answer_end < answer_start:\n",
    "    return \"\"\n",
    "\n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "    \n",
    "  return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lossPlot(trainLosses):\n",
    "  plt.plot(trainLosses, color=\"b\")\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.show()\n",
    "    \n",
    "lossPlot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "def prediction(contents, model):\n",
    "    predAnswers = {}\n",
    "    results = {}\n",
    "    gtAnswers = {}\n",
    "    questions = {}\n",
    "    for data in contents['data']:\n",
    "        for txt in data['paragraphs']:\n",
    "            text = txt['context']\n",
    "            for qa in txt['qas']:\n",
    "                qid = qa['id']\n",
    "                question = qa['question']\n",
    "                answer = predictTheAnswer(text, question, model)\n",
    "                if answer:\n",
    "                    predAnswers[qid] = answer\n",
    "                    questions[qid] = question\n",
    "                    gtAnswers[qid] = [answer['text'] for answer in qa['answers']]\n",
    "\n",
    "    \n",
    "    wer_scores = []\n",
    "\n",
    "    for qid in predAnswers.keys():\n",
    "        if qid in gtAnswers:\n",
    "            wer = jiwer.wer(' '.join(gtAnswers[qid]), ' '.join(predAnswers[qid]))\n",
    "            wer_scores.append(wer)\n",
    "\n",
    "    # Calculate the overall WER\n",
    "    cumulative_wer = sum(wer_scores) / len(wer_scores)\n",
    "\n",
    "    print(f'Cumulative WER: {cumulative_wer:.4f}')\n",
    "\n",
    "    return predAnswers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spoken_test-v1.1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative WER: 14.5372\n"
     ]
    }
   ],
   "source": [
    "jsonVal = \"spoken_test-v1.1.json\"\n",
    "\n",
    "with open(jsonVal, 'r') as j:\n",
    "    squadContents = json.loads(j.read())\n",
    "predAnswers=prediction(squadContents,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZfGtBJbHtXy",
    "tags": []
   },
   "source": [
    "## spoken_test-v1.1_WER44.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Vqec6IvH0NR",
    "outputId": "d8033ab3-d1b6-410e-d5c7-a921a90e5a33",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative WER: 9.4124\n"
     ]
    }
   ],
   "source": [
    "jsonVal = \"spoken_test-v1.1_WER44.json\"\n",
    "with open(jsonVal, 'r') as j:\n",
    "     squadContents = json.loads(j.read())\n",
    "\n",
    "predAnswers=prediction(squadContents,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## spoken_test-v1.1_WER54.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative WER: 8.9901\n"
     ]
    }
   ],
   "source": [
    "jsonVal = \"spoken_test-v1.1_WER54.json\"\n",
    "with open(jsonVal, 'r') as j:\n",
    "     squadContents = json.loads(j.read())\n",
    "\n",
    "predAnswers=prediction(squadContents,model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gts0LAGQvwgT",
    "punU_U_mv7NC",
    "oRusStzkv-nM"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
